import os
import sys
import requests
import gradio as gr
import config
from pathlib import Path
from qdrant_client import QdrantClient
from typing import Optional, Tuple, List
from openai import OpenAI

# –î–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ —Ñ–∞–π–ª–æ–≤
try:
    import docx
    import pypdf
except ImportError:
    print("Warning: python-docx or pypdf not installed. Viewer will be limited.")

DOCS_DIR = os.getenv("DOCS_DIR", "./data")
EMBEDDING_MODEL = os.getenv("OPENROUTER_EMBEDDING_MODEL", "google/gemini-embedding-001")
OPENROUTER_API_KEY = os.getenv("OPENROUTER_API_KEY")

class RAGOrchestrator:
    def __init__(self, qdrant_client: QdrantClient):
        self.qdrant_client = qdrant_client
        
        if not OPENROUTER_API_KEY:
            print("‚ùå –û–®–ò–ë–ö–ê: OPENROUTER_API_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω.")
            self.openai_client = None
        else:
            print(f"–ù–∞—Å—Ç—Ä–æ–π–∫–∞ OpenRouter –∫–ª–∏–µ–Ω—Ç–∞ –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ (–º–æ–¥–µ–ª—å: {EMBEDDING_MODEL})...")
            self.openai_client = OpenAI(
                api_key=OPENROUTER_API_KEY,
                base_url="https://openrouter.ai/api/v1"
            )
        print("‚úÖ –ö–ª–∏–µ–Ω—Ç-–æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ.")

    def get_embedding(self, text: str) -> Optional[list[float]]:
        """–ü–æ–ª—É—á–∞–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥ —á–µ—Ä–µ–∑ OpenRouter."""
        if not self.openai_client:
            print("–ö–ª–∏–µ–Ω—Ç OpenAI –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω.")
            return None
            
        try:
            resp = self.openai_client.embeddings.create(
                model=EMBEDDING_MODEL,
                input=text
            )
            return resp.data[0].embedding
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞: {e}")
            return None

    def query_llm(self, question: str, context: str) -> str:
        """–û–±—Ä–∞—â–∞–µ—Ç—Å—è –∫ LLM-—Å–µ—Ä–≤–∏—Å—É (rag-bot)."""
        result = self._make_api_request(
            config.OPENAI_API_ENDPOINT,
            {"question": question, "context": context},
            "answer",
            "LLM-—Å–µ—Ä–≤–∏—Å—É",
            120
        )
        return result or "–°–µ—Ä–≤–µ—Ä –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç."
    
    def _make_api_request(self, endpoint: str, payload: dict, response_key: str, service_name: str, timeout: int):
        try:
            response = requests.post(endpoint, json=payload, timeout=timeout)
            response.raise_for_status()
            return response.json().get(response_key)
        except requests.exceptions.RequestException as e:
            error_msg = f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ {service_name}: {e}"
            print(error_msg)
            return None if response_key == "embedding" else error_msg

    def process_query(self, question: str) -> Tuple[str, List[str], dict]:
        if not question:
            return "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ –≤–æ–ø—Ä–æ—Å.", [], {}

        self._log_step(1, f"–ü–æ–ª—É—á–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –¥–ª—è –≤–æ–ø—Ä–æ—Å–∞: '{question[:30]}...'")
        question_embedding = self.get_embedding(question)
        if not question_embedding:
            return "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –≤–µ–∫—Ç–æ—Ä –¥–ª—è –≤–æ–ø—Ä–æ—Å–∞.", [], {}
        self._log_completion("—ç–º–±–µ–¥–¥–∏–Ω–≥ –ø–æ–ª—É—á–µ–Ω")

        self._log_step(2, "–ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –≤ Qdrant...")
        structured_context, sources, chunks_map = self._search_and_prepare_context(question_embedding)
        if not structured_context:
            return "–í –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.", [], {}

        self._log_step(3, "–û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –Ω–∞ LLM-—Å–µ—Ä–≤–∏—Å...")
        answer = self.query_llm(question, structured_context)
        self._log_completion("–æ—Ç–≤–µ—Ç –æ—Ç LLM –ø–æ–ª—É—á–µ–Ω")

        return answer, sources, chunks_map
    
    def _search_and_prepare_context(self, question_embedding: list[float]) -> Tuple[list[dict], list[str], dict]:
        search_results = self.qdrant_client.search(
            collection_name=config.COLLECTION_NAME,
            query_vector=question_embedding,
            limit=config.SEARCH_LIMIT,
            with_payload=True
        )
        
        if not search_results:
            return [], [], {}
        
        context_payload = []
        chunks_map = {}
        
        for result in search_results:
            text = result.payload['text']
            fname = result.payload.get('source_file', 'unknown')
            
            context_payload.append({"text": text, "file": fname})
            
            if fname in chunks_map:
                chunks_map[fname] += "\n\n--- –ï–©–ï –û–î–ò–ù –§–†–ê–ì–ú–ï–ù–¢ ---\n\n" + text
            else:
                chunks_map[fname] = text
        
        sources = sorted(list(chunks_map.keys()))[:5]
        self._log_completion(f"–Ω–∞–π–¥–µ–Ω–æ {len(sources)} –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤")
        return context_payload, sources, chunks_map
    
    def _log_step(self, step_num: int, message: str) -> None:
        print(f"\n{step_num}. {message}")
    
    def _log_completion(self, message: str) -> None:
        print(f"   ...{message}.")

def get_file_content(file_name: str) -> str:
    root_path = Path(DOCS_DIR)
    path = root_path / file_name
    
    # If not found directly, try to find it recursively
    if not path.exists():
        found_files = list(root_path.rglob(file_name))
        if found_files:
            path = found_files[0]
        else:
            return f"–§–∞–π–ª '{file_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ {DOCS_DIR} (–∏ –ø–æ–¥–ø–∞–ø–∫–∞—Ö)."
    
    try:
        if path.suffix.lower() == ".docx":
            doc = docx.Document(path)
            return "\n".join([p.text for p in doc.paragraphs])
        elif path.suffix.lower() == ".pdf":
            reader = pypdf.PdfReader(path)
            return "\n".join([page.extract_text() for page in reader.pages])
        else:
            with open(path, "r", encoding="utf-8") as f:
                return f.read()
    except Exception as e:
        return f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {e}"

# --- –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏ –∑–∞–ø—É—Å–∫ Gradio ---
if __name__ == "__main__":
    try:
        print("–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Qdrant...")
        q_client = QdrantClient(host=config.QDRANT_HOST, port=config.QDRANT_PORT)
        orchestrator = RAGOrchestrator(qdrant_client=q_client)

        print("\n–ó–∞–ø—É—Å–∫ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ Gradio...")
        
        with gr.Blocks(title="RAG –ê—Ç–æ–º—Å—Ç—Ä–æ–π–∫–æ–º–ø–ª–µ–∫—Å") as demo:
            gr.Markdown("# üß† RAG-—Å–∏—Å—Ç–µ–º–∞ –¥–ª—è –í–ù–î")
            
            # State to store relevant chunks for the current answer
            chunks_state = gr.State({})

            with gr.Row():
                with gr.Column(scale=1):
                    q_input = gr.Textbox(label="–í–∞—à –≤–æ–ø—Ä–æ—Å", placeholder="–í–≤–µ–¥–∏—Ç–µ –≤–æ–ø—Ä–æ—Å...", lines=3)
                    ask_btn = gr.Button("üîç –ù–∞–π—Ç–∏ –æ—Ç–≤–µ—Ç", variant="primary")
                
                with gr.Column(scale=2):
                    answer_output = gr.Markdown(label="–û—Ç–≤–µ—Ç —Å–∏—Å—Ç–µ–º—ã")
            
            gr.Markdown("### üìö –ò—Å—Ç–æ—á–Ω–∏–∫–∏ –∏ –ø—Ä–æ—Å–º–æ—Ç—Ä –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
            with gr.Row():
                with gr.Column(scale=1):
                    sources_dropdown = gr.Dropdown(label="–ù–∞–π–¥–µ–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã", interactive=True)
                with gr.Column(scale=2):
                    doc_viewer = gr.TextArea(label="–°–æ–¥–µ—Ä–∂–∏–º–æ–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞ (—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç)", lines=15, interactive=False)

            def respond(question):
                ans, srcs, chunks = orchestrator.process_query(question)
                # Select first source if available
                first_src = srcs[0] if srcs else None
                # Get content for first source immediately
                first_content = ""
                if first_src and first_src in chunks:
                    first_content = chunks[first_src]
                
                return ans, gr.update(choices=srcs, value=first_src), chunks, first_content

            def show_source(file_name, chunks):
                if not file_name:
                    return ""
                if chunks and file_name in chunks:
                    return chunks[file_name]
                # Fallback to full content if somehow not in chunks (shouldn't happen for search results)
                return get_file_content(file_name)

            ask_btn.click(
                respond, 
                inputs=q_input, 
                outputs=[answer_output, sources_dropdown, chunks_state, doc_viewer]
            )
            
            sources_dropdown.change(
                show_source, 
                inputs=[sources_dropdown, chunks_state], 
                outputs=doc_viewer
            )
        
        demo.launch(server_name="0.0.0.0", server_port=7860)

    except Exception as e:
        print(f"‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: {e}")