# RAG-Сервис для Работы с Внутренними Документами

## Описание

RAG-сервис (Retrieval-Augmented Generation) представляет собой систему для поиска и генерации ответов на основе внутренних документов организации. Система полностью инкапсулирована в Docker и состоит из трех основных компонентов:

-   **`embedding-service`**: Создает векторные представления (эмбеддинги) текста с использованием API OpenAI.
-   **`rag-bot`**: Генерирует ответы на вопросы, используя LLM (OpenAI GPT или Google Gemini).
-   **`rag-chat`**: Фронтенд-интерфейс на базе Gradio для взаимодействия с пользователем.

## Архитектура

Система спроектирована для работы в изолированном Docker-окружении, что минимизирует зависимости от хост-машины.

```
┌─────────────────────────────────────────────────────────────────────────┐
│ Docker-окружение                                                        │
│                                                                         │
│  ┌──────────────┐   HTTP   ┌───────────────────┐   HTTP   ┌───────────┐  │
│  │   rag-chat   │───► 1. ───┤ embedding-service │───► 2. ───┤ OpenAI    │  │
│  │ (Gradio UI)  │          │   (FastAPI)       │          │ API       │  │
│  │  Port: 7860  │          │    Port: 8001     │          │           │  │
│  └───────┬──────┘          └───────────────────┘          └───────────┘  │
│          │                                                              │
│          │ 3. Поиск в Qdrant                                            │
│          │                                                              │
│          ▼                                                              │
│  ┌──────────────┐   HTTP   ┌───────────────────┐   HTTP   ┌───────────┐  │
│  │   Qdrant DB  │◄─── 4. ───┤      rag-bot      │───► 5. ───┤ OpenAI/   │  │
│  │(Vector Store)│          │     (FastAPI)     │          │ Gemini    │  │
│  │              │          │     Port: 8000    │          │ API       │  │
│  └──────────────┘          └───────────────────┘          └───────────┘  │
│                                                                         │
└─────────────────────────────────────────────────────────────────────────┘
```

### Пошаговый процесс обработки запроса:

1.  **Векторизация вопроса**: `rag-chat` отправляет текст вопроса в `embedding-service`.
2.  **Создание эмбеддинга**: `embedding-service` обращается к API OpenAI для получения векторного представления вопроса.
3.  **Поиск в Qdrant**: `rag-chat` использует полученный вектор для поиска релевантных документов в векторной базе данных Qdrant.
4.  **Запрос к LLM**: `rag-chat` формирует запрос, включающий исходный вопрос и найденный контекст, и отправляет его в `rag-bot`.
5.  **Генерация ответа**: `rag-bot` обращается к API OpenAI или Gemini для генерации ответа и возвращает его пользователю.

## Конфигурация

### Переменные окружения (`.env`)

Для работы сервиса необходимо создать файл `.env` в директории `rag-bot/`. Этот файл используется всеми сервисами внутри Docker.

```bash
# Ключ для доступа к API OpenAI. Используется для генерации ответов и создания эмбеддингов.
OPENAI_API_KEY="sk-..."

# (Опционально) Ключ для доступа к API Google Gemini. Нужен, если вы планируете использовать модели Gemini.
GEMINI_API_KEY="..."

# (Опционально) Укажите модель OpenAI для создания эмбеддингов.
# По умолчанию используется "text-embedding-3-small".
OPENAI_EMBEDDING_MODEL="text-embedding-3-large"
```

### Конфигурация моделей (`rag-bot/config.json`)

Файл `rag-bot/config.json` позволяет настроить, какие модели будут использоваться для генерации ответов.

```json
{
  "model_provider": "openai",
  "openai_model": "gpt-4o-mini",
  "gemini_model": "gemini-1.5-flash",
  "temperature": 0.1
}
```

-   `model_provider`: Провайдер по умолчанию (`openai` или `gemini`).
-   `openai_model`: Модель от OpenAI.
-   `gemini_model`: Модель от Gemini.

## Установка и запуск

1.  **Создайте и настройте `rag-bot/.env`** с вашими API-ключами, как описано выше.
2.  **Запустите систему** с помощью Docker Compose:
    ```bash
    docker-compose up -d --build
    ```

### Доступ к сервисам:

-   **Gradio интерфейс:** [http://localhost:7860](http://localhost:7860)
-   **Документация `rag-bot`:** [http://localhost:8000/docs](http://localhost:8000/docs)
-   **Документация `embedding-service`:** [http://localhost:8001/docs](http://localhost:8001/docs)

## Структура проекта

```
rag-service/
├── docker-compose.yml
├── README.md
├── embedding_service/
│   ├── main.py
│   ├── requirements.txt
│   └── Dockerfile
├── rag-bot/
│   ├── ask_question.py
│   ├── config.json
│   ├── system_prompt.txt
│   ├── requirements.txt
│   ├── Dockerfile
│   └── .env            # <-- ВАЖНО: не версионируется
└── rag-chat/
    ├── main_app.py
    ├── config.py
    ├── requirements.txt
    └── Dockerfile
```